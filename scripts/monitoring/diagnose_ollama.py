# scripts/monitoring/diagnose_ollama.py
#!/usr/bin/env python3
"""Script de diagnostic pour identifier les problÃ¨mes de rÃ©ponse avec Ollama.

Ce script est particuliÃ¨rement utile pour dÃ©boguer les cas oÃ¹ un modÃ¨le Ollama
(comme StarCoder2) ne retourne pas de rÃ©ponse ou retourne une rÃ©ponse vide.
Il teste systÃ©matiquement diffÃ©rentes configurations pour isoler le problÃ¨me :
- ConnectivitÃ© de base au serveur Ollama.
- Liste des modÃ¨les disponibles.
- DiffÃ©rentes variantes de noms de modÃ¨les.
- Endpoints API (`/api/generate` vs `/api/chat`).
- Formats de prompt.
- ParamÃ¨tres d'infÃ©rence (tempÃ©rature, seed, etc.).

Ã€ la fin, il gÃ©nÃ¨re un rÃ©sumÃ© avec des statistiques et des recommandations.
"""
import asyncio
import aiohttp
import json
import logging
import os
from datetime import datetime
from typing import Dict, List, Optional

# Configuration du logging dÃ©taillÃ© pour le diagnostic.
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class OllamaDiagnostic:
    """Outil de diagnostic pour les problÃ¨mes de communication avec Ollama."""
    
    def __init__(self, ollama_host: Optional[str] = None):
        """Initialise l'outil de diagnostic."""
        self.ollama_host = ollama_host or os.environ.get("OLLAMA_HOST", "http://localhost:11434")
        self.session: Optional[aiohttp.ClientSession] = None
        self.results: List[Tuple[str, str, Optional[str]]] = []
        
    async def initialize(self):
        """Initialise la session client HTTP asynchrone."""
        self.session = aiohttp.ClientSession()
        logger.info(f"Session initialisÃ©e pour l'hÃ´te Ollama : {self.ollama_host}")
        
    async def run_diagnostics(self):
        """Lance la suite complÃ¨te de tests de diagnostic."""
        print("\n" + "="*60)
        logger.info("ðŸ” DÃ‰MARRAGE DU DIAGNOSTIC OLLAMA")
        print("="*60)
        
        await self.test_connectivity()
        await self.list_models()
        await self.test_starcoder_variants()
        await self.test_api_endpoints()
        await self.test_prompt_formats()
        await self.test_parameters()
        
        self.print_summary()
        
    async def test_connectivity(self):
        """Teste la connectivitÃ© de base au serveur Ollama."""
        logger.info("\n1ï¸âƒ£ Test de connectivitÃ©...")
        if not self.session:
            return

        try:
            async with self.session.get(f"{self.ollama_host}/", timeout=5) as resp:
                if resp.status == 200:
                    logger.info("âœ… Le serveur Ollama est accessible.")
                    self.results.append(("ConnectivitÃ©", "OK", None))
                else:
                    logger.warning(f"âŒ Le serveur Ollama a rÃ©pondu avec le statut : {resp.status}")
                    self.results.append(("ConnectivitÃ©", "FAIL", f"Statut {resp.status}"))
        except Exception as e:
            logger.error(f"âŒ Erreur critique de connexion Ã  Ollama : {e}")
            self.results.append(("ConnectivitÃ©", "FAIL", str(e)))
            
    async def list_models(self) -> List[str]:
        """RÃ©cupÃ¨re et affiche la liste des modÃ¨les installÃ©s sur le serveur Ollama."""
        logger.info("\n2ï¸âƒ£ Liste des modÃ¨les disponibles...")
        if not self.session:
            return []

        try:
            async with self.session.get(f"{self.ollama_host}/api/tags") as resp:
                resp.raise_for_status()
                data = await resp.json()
                models = data.get('models', [])
                
                starcoder_models = [m['name'] for m in models if 'starcoder' in m.get('name', '').lower()]
                logger.info(f"  TrouvÃ© {len(models)} modÃ¨les, dont {len(starcoder_models)} variantes de StarCoder.")
                for model in models:
                    logger.info(f"    - {model.get('name')}")
                
                self.results.append(("Liste des modÃ¨les", "OK", f"{len(models)} modÃ¨les trouvÃ©s"))
                return [m['name'] for m in models]
        except Exception as e:
            logger.error(f"âŒ Impossible de lister les modÃ¨les : {e}")
            self.results.append(("Liste des modÃ¨les", "FAIL", str(e)))
        return []
        
    async def test_starcoder_variants(self):
        """Teste diffÃ©rentes variantes de noms pour le modÃ¨le StarCoder."""
        logger.info("\n3ï¸âƒ£ Test des variantes de StarCoder...")
        variants = ["starcoder2-playwright", "starcoder2:15b-q8_0", "starcoder2", "starcoder"]
        for variant in variants:
            success = await self._test_single_model(variant)
            logger.info(f"  - Test de `{variant}`: {'âœ… SuccÃ¨s' if success else 'âŒ Ã‰chec'}")
                
    async def _test_single_model(self, model_name: str) -> bool:
        """Sous-test pour un modÃ¨le spÃ©cifique, retourne True si une rÃ©ponse est reÃ§ue."""
        if not self.session:
            return False

        try:
            payload = {"model": model_name, "prompt": "def hello():\n  pass", "stream": False, "options": {"num_predict": 10}}
            async with self.session.post(f"{self.ollama_host}/api/generate", json=payload, timeout=20) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    if data.get("response"):
                        self.results.append((f"ModÃ¨le `{model_name}`", "OK", f"{len(data['response'])} chars"))
                        return True
                    else:
                        self.results.append((f"ModÃ¨le `{model_name}`", "EMPTY", "RÃ©ponse vide"))
                else:
                    self.results.append((f"ModÃ¨le `{model_name}`", "FAIL", f"Statut {resp.status}"))
        except Exception as e:
            self.results.append((f"ModÃ¨le `{model_name}`", "ERROR", str(e)[:60]))
        return False

    # ... [Le reste des mÃ©thodes de test avec des docstrings similaires] ...

    def print_summary(self):
        """Affiche un rÃ©sumÃ© clair et concis des rÃ©sultats du diagnostic."""
        print("\n" + "="*60)
        logger.info("ðŸ“Š RÃ‰SUMÃ‰ DU DIAGNOSTIC")
        print("="*60)
        
        total = len(self.results)
        ok = sum(1 for _, status, _ in self.results if status == "OK")
        fail = sum(1 for _, status, _ in self.results if status in ["FAIL", "ERROR"])
        empty = sum(1 for _, status, _ in self.results if status == "EMPTY")
        
        logger.info(f"\nðŸ“ˆ Statistiques:")
        logger.info(f"  - Tests effectuÃ©s : {total}")
        logger.info(f"  - âœ… SuccÃ¨s         : {ok}")
        logger.info(f"  - âŒ Ã‰checs         : {fail}")
        logger.info(f"  - ðŸ“­ RÃ©ponses vides : {empty}")
        
        logger.info(f"\nðŸ’¡ Recommandations:")
        if fail > 0:
            logger.info("  - VÃ©rifiez que le serveur Ollama est bien lancÃ© et accessible Ã  l'adresse configurÃ©e.")
            logger.info("  - Consultez les logs du serveur Ollama (`journalctl -u ollama -f` sur Linux).")
        if empty > 0:
            logger.info("  - Le problÃ¨me de rÃ©ponse vide est confirmÃ©. Cela peut venir d'un Modelfile mal configurÃ©.")
            logger.info("  - Essayez de recrÃ©er le modÃ¨le avec `ollama create ...`.")
            logger.info("  - Testez l'API `/api/chat` qui est parfois plus robuste que `/api/generate`.")
        if ok > 0 and (fail > 0 or empty > 0):
            logger.info("  - Certaines configurations fonctionnent. Notez lesquelles et utilisez-les.")
        elif ok == total:
            logger.info("  - Tous les tests de base semblent passer. Le problÃ¨me est peut-Ãªtre plus subtil (prompt, paramÃ¨tres spÃ©cifiques).")

    async def close(self):
        """Ferme la session client HTTP."""
        if self.session:
            await self.session.close()


async def main():
    """Point d'entrÃ©e principal pour lancer le script de diagnostic."""
    diagnostic = OllamaDiagnostic()
    try:
        await diagnostic.initialize()
        await diagnostic.run_diagnostics()
    except Exception as e:
        logger.critical(f"Erreur fatale durant le diagnostic : {e}", exc_info=True)
    finally:
        await diagnostic.close()
    logger.info("\nâœ… Diagnostic terminÃ©.")


if __name__ == "__main__":
    logger.info("ðŸš€ Lancement du script de diagnostic pour Ollama. Cela peut prendre quelques minutes...")
    asyncio.run(main())